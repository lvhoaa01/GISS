{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62718269-aa03-47bb-b46f-52b1731871cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ƒêANG N·∫†P D·ªÆ LI·ªÜU T·ª™: 6_DSCanhKQ2_CanTho_XoaCon3Cot_XoaDongTrung.txt ---\n",
      "üîÑ ƒêang chuy·ªÉn ƒë·ªïi sang Adjacency Dictionary...\n",
      "‚úÖ ƒê√£ n·∫°p th√†nh c√¥ng: 2434 ƒë·ªânh.\n",
      "\n",
      "===============================================================================================\n",
      "                     BENCHMARK TRUNG TH·ª∞C (RAW RESULTS) - KH√îNG R√ÄNG BU·ªòC                      \n",
      "===============================================================================================\n",
      "| Eps    | MinPts | G·ªëc (ms)        | C·∫£i ti·∫øn (ms)   | Nhanh h∆°n (%)   |\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| 200    | 20     | 69.07           | 67.66           | 2.05            |\n",
      "| 200    | 25     | 68.62           | 74.49           | -8.55           |\n",
      "| 200    | 30     | 66.73           | 69.27           | -3.81           |\n",
      "| 200    | 35     | 64.85           | 65.52           | -1.03           |\n",
      "| 200    | 40     | 65.00           | 66.14           | -1.75           |\n",
      "| 250    | 20     | 87.24           | 88.40           | -1.33           |\n",
      "| 250    | 25     | 89.09           | 85.52           | 4.00            |\n",
      "| 250    | 30     | 86.30           | 84.36           | 2.25            |\n",
      "| 250    | 35     | 89.98           | 87.20           | 3.10            |\n",
      "| 250    | 40     | 90.89           | 93.69           | -3.08           |\n",
      "| 300    | 20     | 114.08          | 127.94          | -12.15          |\n",
      "| 300    | 25     | 124.24          | 122.68          | 1.26            |\n",
      "| 300    | 30     | 235.82          | 154.77          | 34.37           |\n",
      "| 300    | 35     | 151.57          | 175.74          | -15.95          |\n",
      "| 300    | 40     | 111.64          | 115.21          | -3.19           |\n",
      "| 350    | 20     | 136.38          | 139.50          | -2.29           |\n",
      "| 350    | 25     | 138.24          | 134.58          | 2.65            |\n",
      "| 350    | 30     | 138.82          | 131.64          | 5.18            |\n",
      "| 350    | 35     | 136.41          | 133.60          | 2.05            |\n",
      "| 350    | 40     | 134.77          | 132.23          | 1.88            |\n",
      "| 400    | 20     | 162.64          | 161.47          | 0.71            |\n",
      "| 400    | 25     | 164.76          | 163.08          | 1.02            |\n",
      "| 400    | 30     | 175.29          | 160.22          | 8.60            |\n",
      "| 400    | 35     | 160.02          | 160.12          | -0.06           |\n",
      "| 400    | 40     | 160.37          | 160.55          | -0.11           |\n",
      "===============================================================================================\n",
      "‚úÖ K·∫øt qu·∫£ chi ti·∫øt ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: D:\\GISS\\data\\KetQua_Raw_Benchmark.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import heapq\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. C·∫§U H√åNH & D·ªÆ LI·ªÜU\n",
    "# ==============================================================================\n",
    "\n",
    "# --- ƒê∆Ø·ªúNG D·∫™N D·ªÆ LI·ªÜU ---\n",
    "DATA_FILE = r'D:/GISS/data/6_DSCanhKQ2_CanTho_XoaCon3Cot_XoaDongTrung.txt'\n",
    "\n",
    "# L∆∞u √Ω: INPUT v√† OUTPUT d√πng ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi ho·∫∑c tuy·ªát ƒë·ªëi ƒë·ªÅu ƒë∆∞·ª£c\n",
    "# Code s·∫Ω t·ª± ƒë·ªông t·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥\n",
    "INPUT_CSV = r'D:/GISS/data/DataForCmp_GIS.csv'      \n",
    "\n",
    "# 3. File k·∫øt qu·∫£ ƒë·∫ßu ra\n",
    "OUTPUT_CSV = r'D:/GISS/data/KetQua_Raw_Benchmark.csv'\n",
    "\n",
    "NUM_RUNS = 3 \n",
    "\n",
    "# H√†m h·ªó tr·ª£ t·∫°o th∆∞ m·ª•c an to√†n\n",
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if directory and not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        print(f\"üìÅ ƒê√£ t·∫°o th∆∞ m·ª•c: {directory}\")\n",
    "\n",
    "def load_graph_data(path):\n",
    "    print(f\"--- ƒêANG N·∫†P D·ªÆ LI·ªÜU T·ª™: {os.path.basename(path)} ---\")\n",
    "    try:\n",
    "        # ƒê·ªçc file (h·ªó tr·ª£ c·∫£ tab v√† space)\n",
    "        df = pd.read_csv(path, sep='\\t', engine='python')\n",
    "        if df.shape[1] < 3: \n",
    "            df = pd.read_csv(path, delim_whitespace=True, engine='python')\n",
    "        \n",
    "        df.columns = df.columns.str.strip()\n",
    "        if 'IdStar' in df.columns: df.rename(columns={'IdStar': 'IdStart'}, inplace=True)\n",
    "        \n",
    "        # Ki·ªÉm tra c·ªôt b·∫Øt bu·ªôc\n",
    "        if not {'IdStart', 'IdEnd', 'Length'}.issubset(df.columns):\n",
    "            print(f\"‚ùå File thi·∫øu c·ªôt! C√°c c·ªôt t√¨m th·∫•y: {list(df.columns)}\")\n",
    "            return None, None\n",
    "\n",
    "        # Chuy·ªÉn sang Dictionary\n",
    "        print(\"üîÑ ƒêang chuy·ªÉn ƒë·ªïi sang Adjacency Dictionary...\")\n",
    "        adj = {}\n",
    "        nodes = set()\n",
    "        for _, row in df.iterrows():\n",
    "            u, v, w = int(row['IdStart']), int(row['IdEnd']), float(row['Length'])\n",
    "            if u not in adj: adj[u] = []\n",
    "            if v not in adj: adj[v] = []\n",
    "            adj[u].append((v, w))\n",
    "            adj[v].append((u, w))\n",
    "            nodes.add(u); nodes.add(v)\n",
    "            \n",
    "        print(f\"‚úÖ ƒê√£ n·∫°p th√†nh c√¥ng: {len(nodes)} ƒë·ªânh.\")\n",
    "        return adj, list(nodes)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói n·∫°p d·ªØ li·ªáu: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. THU·∫¨T TO√ÅN G·ªêC (NS-DBSCAN STANDARD)\n",
    "# ==============================================================================\n",
    "\n",
    "def alg1_LSPD_original(adj, start_node, eps):\n",
    "    distances = {start_node: 0}\n",
    "    queue = [(0, start_node)]\n",
    "    neighbors = []\n",
    "    \n",
    "    while queue:\n",
    "        d, u = heapq.heappop(queue)\n",
    "        if d > eps: continue \n",
    "        neighbors.append(u)\n",
    "        \n",
    "        if u in adj:\n",
    "            for v, weight in adj[u]:\n",
    "                new_d = d + weight\n",
    "                if new_d <= eps:\n",
    "                    if new_d < distances.get(v, float('inf')):\n",
    "                        distances[v] = new_d\n",
    "                        heapq.heappush(queue, (new_d, v))\n",
    "    return neighbors\n",
    "\n",
    "def alg2_density_ordering_original(adj, points, eps):\n",
    "    neighbors_cache = {}\n",
    "    ordered_list = []\n",
    "    for p in points:\n",
    "        nbrs = alg1_LSPD_original(adj, p, eps)\n",
    "        neighbors_cache[p] = nbrs\n",
    "        ordered_list.append((len(nbrs), p))\n",
    "    ordered_list.sort(key=lambda x: x[0], reverse=True)\n",
    "    return ordered_list, neighbors_cache\n",
    "\n",
    "def alg3_clustering_original(ordered_list, neighbors_cache, min_pts):\n",
    "    labels = {} \n",
    "    cluster_id = 0\n",
    "    sorted_points = [x[1] for x in ordered_list]\n",
    "    for p in sorted_points:\n",
    "        if p in labels: continue \n",
    "        p_nbrs = neighbors_cache.get(p, [])\n",
    "        if len(p_nbrs) >= min_pts:\n",
    "            cluster_id += 1\n",
    "            labels[p] = cluster_id \n",
    "            seeds = list(p_nbrs)\n",
    "            i = 0\n",
    "            while i < len(seeds):\n",
    "                q = seeds[i]\n",
    "                if q not in labels:\n",
    "                    labels[q] = cluster_id\n",
    "                    q_nbrs = neighbors_cache.get(q, [])\n",
    "                    if len(q_nbrs) >= min_pts:\n",
    "                        seeds.extend(q_nbrs)\n",
    "                elif labels[q] == -1: \n",
    "                    labels[q] = cluster_id \n",
    "                i += 1\n",
    "        else:\n",
    "            labels[p] = -1 \n",
    "    return labels\n",
    "\n",
    "def run_ns_dbscan_original(adj, points, eps, min_pts):\n",
    "    ordered_list, nbr_cache = alg2_density_ordering_original(adj, points, eps)\n",
    "    labels = alg3_clustering_original(ordered_list, nbr_cache, min_pts)\n",
    "    return labels\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. THU·∫¨T TO√ÅN C·∫¢I TI·∫æN (iNS-DBSCAN)\n",
    "# ==============================================================================\n",
    "\n",
    "def alg1_LSPD_improved(adj, start_node, eps):\n",
    "    distances = {start_node: 0}\n",
    "    queue = [(0, start_node)]\n",
    "    neighbors = []\n",
    "    while queue:\n",
    "        d, u = heapq.heappop(queue)\n",
    "        if d > eps: continue\n",
    "        neighbors.append(u)\n",
    "        if u in adj:\n",
    "            for v, weight in adj[u]:\n",
    "                if weight > eps: continue # C·∫¢I TI·∫æN 1: Pruning\n",
    "                new_d = d + weight\n",
    "                if new_d <= eps:\n",
    "                    if new_d < distances.get(v, float('inf')):\n",
    "                        distances[v] = new_d\n",
    "                        heapq.heappush(queue, (new_d, v))\n",
    "    return neighbors\n",
    "\n",
    "def alg2_density_ordering_improved(adj, points, eps):\n",
    "    neighbors_cache = {}\n",
    "    ordered_list = []\n",
    "    n = len(points)\n",
    "    threshold = math.log(n) if n > 0 else 0 # C·∫¢I TI·∫æN 2A: Threshold\n",
    "    \n",
    "    for p in points:\n",
    "        nbrs = alg1_LSPD_improved(adj, p, eps)\n",
    "        if len(nbrs) >= threshold: # C·∫¢I TI·∫æN 2B: Filtering\n",
    "            neighbors_cache[p] = nbrs\n",
    "            ordered_list.append((len(nbrs), p))\n",
    "            \n",
    "    ordered_list.sort(key=lambda x: x[0], reverse=True)\n",
    "    return ordered_list, neighbors_cache\n",
    "\n",
    "def alg3_clustering_improved(ordered_list, neighbors_cache, min_pts):\n",
    "    labels = {}\n",
    "    cluster_id = 0\n",
    "    sorted_points = [x[1] for x in ordered_list]\n",
    "    for p in sorted_points:\n",
    "        if p in labels: continue\n",
    "        p_nbrs = neighbors_cache.get(p, [])\n",
    "        if len(p_nbrs) >= min_pts:\n",
    "            cluster_id += 1\n",
    "            labels[p] = cluster_id\n",
    "            seeds = list(p_nbrs)\n",
    "            i = 0\n",
    "            while i < len(seeds):\n",
    "                q = seeds[i]\n",
    "                if q not in labels: # C·∫¢I TI·∫æN 3: Implicit Noise\n",
    "                    labels[q] = cluster_id\n",
    "                    q_nbrs = neighbors_cache.get(q, [])\n",
    "                    if len(q_nbrs) >= min_pts:\n",
    "                        seeds.extend(q_nbrs)\n",
    "                i += 1\n",
    "    return labels\n",
    "\n",
    "def run_ns_dbscan_improved(adj, points, eps, min_pts):\n",
    "    ordered_list, nbr_cache = alg2_density_ordering_improved(adj, points, eps)\n",
    "    labels = alg3_clustering_improved(ordered_list, nbr_cache, min_pts)\n",
    "    return labels\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. BENCHMARK ENGINE\n",
    "# ==============================================================================\n",
    "def measure_time(func, *args):\n",
    "    gc.collect() \n",
    "    start = time.time()\n",
    "    func(*args)\n",
    "    end = time.time()\n",
    "    return (end - start) * 1000 \n",
    "\n",
    "def run_raw_benchmark():\n",
    "    if not os.path.exists(DATA_FILE):\n",
    "        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu: {DATA_FILE}\")\n",
    "        return\n",
    "    \n",
    "    adj, nodes = load_graph_data(DATA_FILE)\n",
    "    if not adj: return\n",
    "\n",
    "    # --- S·ª¨A L·ªñI ·ªû ƒê√ÇY: ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i tr∆∞·ªõc khi t·∫°o file ---\n",
    "    ensure_dir(INPUT_CSV) \n",
    "    \n",
    "    if not os.path.exists(INPUT_CSV):\n",
    "        pd.DataFrame({\n",
    "            'Eps': [100, 200, 300, 400, 500],\n",
    "            'MinPts': [5, 10, 15, 20, 25]\n",
    "        }).to_csv(INPUT_CSV, index=False)\n",
    "        print(\"‚ö†Ô∏è ƒê√£ t·∫°o file tham s·ªë m·∫´u.\")\n",
    "\n",
    "    df_params = pd.read_csv(INPUT_CSV)\n",
    "    results = []\n",
    "\n",
    "    print(\"\\n\" + \"=\"*95)\n",
    "    print(f\"{'BENCHMARK TRUNG TH·ª∞C (RAW RESULTS) - KH√îNG R√ÄNG BU·ªòC':^95}\")\n",
    "    print(\"=\"*95)\n",
    "    print(f\"| {'Eps':<6} | {'MinPts':<6} | {'G·ªëc (ms)':<15} | {'C·∫£i ti·∫øn (ms)':<15} | {'Nhanh h∆°n (%)':<15} |\")\n",
    "    print(\"-\" * 95)\n",
    "\n",
    "    for _, row in df_params.iterrows():\n",
    "        eps = float(row['Eps'])\n",
    "        min_pts = int(row['MinPts'])\n",
    "        \n",
    "        total_orig = 0\n",
    "        total_imp = 0\n",
    "        \n",
    "        for _ in range(NUM_RUNS):\n",
    "            total_orig += measure_time(run_ns_dbscan_original, adj, nodes, eps, min_pts)\n",
    "            total_imp += measure_time(run_ns_dbscan_improved, adj, nodes, eps, min_pts)\n",
    "            \n",
    "        avg_orig = total_orig / NUM_RUNS\n",
    "        avg_imp = total_imp / NUM_RUNS\n",
    "        \n",
    "        improvement = ((avg_orig - avg_imp) / avg_orig) * 100 if avg_orig > 0 else 0\n",
    "        \n",
    "        print(f\"| {int(eps):<6} | {min_pts:<6} | {avg_orig:<15.2f} | {avg_imp:<15.2f} | {improvement:<15.2f} |\")\n",
    "        \n",
    "        results.append({\n",
    "            'Eps': eps,\n",
    "            'MinPts': min_pts,\n",
    "            'Original_Time_ms': round(avg_orig, 3),\n",
    "            'Improved_Time_ms': round(avg_imp, 3),\n",
    "            'Improvement_Percent': round(improvement, 2)\n",
    "        })\n",
    "\n",
    "    # --- S·ª¨A L·ªñI ·ªû ƒê√ÇY: ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i tr∆∞·ªõc khi l∆∞u k·∫øt qu·∫£ ---\n",
    "    ensure_dir(OUTPUT_CSV)\n",
    "    pd.DataFrame(results).to_csv(OUTPUT_CSV, index=False)\n",
    "    print(\"=\"*95)\n",
    "    print(f\"‚úÖ K·∫øt qu·∫£ chi ti·∫øt ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {os.path.abspath(OUTPUT_CSV)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_raw_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86312a49-98c4-4674-9cec-c7cbadb673b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
