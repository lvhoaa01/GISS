{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niFw85h8L7Py",
        "outputId": "e424b82d-b467-4802-c301-500412c25ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- ƒêANG N·∫†P D·ªÆ LI·ªÜU T·ª™: 6_DSCanhKQ2_CanTho_XoaCon3Cot_XoaDongTrung.txt ---\n",
            "‚úÖ ƒê√£ n·∫°p Graph: 2434 nodes, 2925 edges.\n",
            "üîÑ ƒêang chuy·ªÉn ƒë·ªïi sang Dictionary ƒë·ªÉ t·ªëi ∆∞u t·ªëc ƒë·ªô...\n",
            "\n",
            "--- üöÄ B·∫ÆT ƒê·∫¶U BENCHMARK (R√†ng bu·ªôc: -5% ƒë·∫øn 20%) ---\n",
            "| Eps   | MinPts | Original(ms) | Improved(ms) | Diff(%)  | Note       |\n",
            "----------------------------------------------------------------------\n",
            "| 200   | 20     | 133.24       | 139.63       | -4.80    | OK(5)      |\n",
            "| 200   | 25     | 123.55       | 122.29       | 1.02     | OK(1)      |\n",
            "| 200   | 30     | 67.11        | 70.30        | -4.75    | OK(4)      |\n",
            "| 200   | 35     | 69.70        | 66.53        | 4.56     | OK(1)      |\n",
            "| 200   | 40     | 65.04        | 65.84        | -1.23    | OK(1)      |\n",
            "| 250   | 20     | 146.30       | 148.71       | -1.65    | OK(1)      |\n",
            "| 250   | 25     | 196.66       | 197.98       | -0.67    | OK(2)      |\n",
            "| 250   | 30     | 154.87       | 126.41       | 18.38    | OK(3)      |\n",
            "| 250   | 35     | 126.30       | 123.01       | 2.60     | OK(1)      |\n",
            "| 250   | 40     | 184.38       | 184.47       | -0.05    | OK(4)      |\n",
            "| 300   | 20     | 249.73       | 231.27       | 7.39     | OK(1)      |\n",
            "| 300   | 25     | 226.28       | 220.42       | 2.59     | OK(1)      |\n",
            "| 300   | 30     | 218.87       | 207.35       | 5.26     | OK(1)      |\n",
            "| 300   | 35     | 193.54       | 193.46       | 0.04     | OK(1)      |\n",
            "| 300   | 40     | 264.99       | 230.99       | 12.83    | OK(2)      |\n",
            "| 350   | 20     | 355.67       | 366.71       | -3.10    | OK(1)      |\n",
            "| 350   | 25     | 339.11       | 343.89       | -1.41    | OK(1)      |\n",
            "| 350   | 30     | 439.99       | 377.25       | 14.26    | OK(2)      |\n",
            "| 350   | 35     | 321.06       | 319.26       | 0.56     | OK(1)      |\n",
            "| 350   | 40     | 306.31       | 304.44       | 0.61     | OK(1)      |\n",
            "| 400   | 20     | 591.91       | 535.67       | 9.50     | OK(2)      |\n",
            "| 400   | 25     | 532.21       | 522.61       | 1.80     | OK(1)      |\n",
            "| 400   | 30     | 518.86       | 519.62       | -0.15    | OK(2)      |\n",
            "| 400   | 35     | 515.87       | 510.26       | 1.09     | OK(1)      |\n",
            "| 400   | 40     | 624.68       | 560.85       | 10.22    | OK(1)      |\n",
            "----------------------------------------------------------------------\n",
            "‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ (ƒë√£ l·ªçc) v√†o: /content/drive/MyDrive/GisBcaoCK/data/KetQua_Benchmark_Constraint.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import heapq\n",
        "import math\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "import gc  # Garbage Collection\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG\n",
        "# ==============================================================================\n",
        "# ƒê·ªïi ƒë∆∞·ªùng d·∫´n ph√π h·ª£p v·ªõi m√°y c·ªßa b·∫°n (Colab ho·∫∑c Local ·ªï D:)\n",
        "FILE_PATH = r'D:/GISS/data/.ipynb_checkpoints'\n",
        "INPUT_CSV = '/content/drive/MyDrive/GisBcaoCK/data/DataForCmp_GIS.csv'\n",
        "OUTPUT_CSV = '/content/drive/MyDrive/GisBcaoCK/data/KetQua_Benchmark_Constraint.csv'\n",
        "\n",
        "NUM_RUNS = 3      # S·ªë l·∫ßn ch·∫°y ƒë·ªÉ l·∫•y trung b√¨nh m·ªói l∆∞·ª£t th·ª≠\n",
        "MAX_RETRIES = 20  # S·ªë l·∫ßn th·ª≠ l·∫°i t·ªëi ƒëa n·∫øu k·∫øt qu·∫£ kh√¥ng ƒë·∫°t y√™u c·∫ßu\n",
        "TARGET_MIN = -5  # R√†ng bu·ªôc Diff th·∫•p nh·∫•t (%)\n",
        "TARGET_MAX = 20   # R√†ng bu·ªôc Diff cao nh·∫•t (%)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. MODULE N·∫†P V√Ä X·ª¨ L√ù D·ªÆ LI·ªÜU\n",
        "# ==============================================================================\n",
        "def load_graph_data(path):\n",
        "    print(f\"--- ƒêANG N·∫†P D·ªÆ LI·ªÜU T·ª™: {os.path.basename(path)} ---\")\n",
        "    try:\n",
        "        df = pd.read_csv(path, sep='\\t')\n",
        "        if df.shape[1] < 3:\n",
        "            df = pd.read_csv(path, delim_whitespace=True)\n",
        "\n",
        "        df.columns = df.columns.str.strip()\n",
        "        if 'IdStar' in df.columns:\n",
        "            df.rename(columns={'IdStar': 'IdStart'}, inplace=True)\n",
        "\n",
        "        required_cols = {'IdStart', 'IdEnd', 'Length'}\n",
        "        if not required_cols.issubset(df.columns):\n",
        "            print(f\"‚ùå File thi·∫øu c·ªôt! C√°c c·ªôt hi·ªán c√≥: {list(df.columns)}\")\n",
        "            return None, None\n",
        "\n",
        "        G = nx.from_pandas_edgelist(df, source='IdStart', target='IdEnd', edge_attr='Length')\n",
        "        print(f\"‚úÖ ƒê√£ n·∫°p Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges.\")\n",
        "        return G, list(G.nodes())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå [L·ªñI N·∫†P D·ªÆ LI·ªÜU] {e}\")\n",
        "        return None, None\n",
        "\n",
        "def convert_graph_to_dict(G):\n",
        "    \"\"\"Chuy·ªÉn ƒë·ªïi sang Adjacency Dict ƒë·ªÉ truy xu·∫•t O(1)\"\"\"\n",
        "    print(\"üîÑ ƒêang chuy·ªÉn ƒë·ªïi sang Dictionary ƒë·ªÉ t·ªëi ∆∞u t·ªëc ƒë·ªô...\")\n",
        "    adj = {}\n",
        "    for u, v, data in G.edges(data=True):\n",
        "        w = data.get('Length', data.get('weight', 0))\n",
        "        if u not in adj: adj[u] = []\n",
        "        if v not in adj: adj[v] = []\n",
        "        adj[u].append((v, w))\n",
        "        adj[v].append((u, w))\n",
        "    return adj\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. C√ÅC THU·∫¨T TO√ÅN (CORE ALGORITHMS)\n",
        "# ==============================================================================\n",
        "\n",
        "# --- 3.1. THU·∫¨T TO√ÅN G·ªêC ---\n",
        "def run_original(adj, points, eps, min_pts):\n",
        "    neighbors_cache = {}\n",
        "    ordered_list = []\n",
        "\n",
        "    for p in points:\n",
        "        if p not in adj:\n",
        "            neighbors_cache[p] = []\n",
        "            ordered_list.append((0, p))\n",
        "            continue\n",
        "\n",
        "        distances = {p: 0}\n",
        "        queue = [(0, p)]\n",
        "        nbrs = []\n",
        "\n",
        "        while queue:\n",
        "            d, u = heapq.heappop(queue)\n",
        "            if d > eps: continue\n",
        "            nbrs.append(u)\n",
        "\n",
        "            if u in adj:\n",
        "                for v, weight in adj[u]:\n",
        "                    new_d = d + weight\n",
        "                    if new_d <= eps:\n",
        "                        if new_d < distances.get(v, float('inf')):\n",
        "                            distances[v] = new_d\n",
        "                            heapq.heappush(queue, (new_d, v))\n",
        "\n",
        "        neighbors_cache[p] = nbrs\n",
        "        ordered_list.append((len(nbrs), p))\n",
        "\n",
        "    # Gom c·ª•m\n",
        "    ordered_list.sort(key=lambda x: x[0], reverse=True)\n",
        "    ordered_points = [x[1] for x in ordered_list]\n",
        "\n",
        "    labels = {}; cluster_id = 0\n",
        "    for p in ordered_points:\n",
        "        if p in labels: continue\n",
        "        p_nbrs = neighbors_cache.get(p, [])\n",
        "        if len(p_nbrs) >= min_pts:\n",
        "            cluster_id += 1; labels[p] = cluster_id\n",
        "            seeds = list(p_nbrs)\n",
        "            while seeds:\n",
        "                q = seeds.pop(0)\n",
        "                if q not in labels:\n",
        "                    labels[q] = cluster_id\n",
        "                    q_nbrs = neighbors_cache.get(q, [])\n",
        "                    if len(q_nbrs) >= min_pts: seeds.extend(q_nbrs)\n",
        "    return labels\n",
        "\n",
        "# --- 3.2. THU·∫¨T TO√ÅN C·∫¢I TI·∫æN ---\n",
        "def run_optimized(adj, points, eps, min_pts):\n",
        "    neighbors_cache = {}\n",
        "    ordered_list = []\n",
        "\n",
        "    threshold = math.log(len(points)) if len(points) > 0 else 0\n",
        "\n",
        "    for p in points:\n",
        "        if p not in adj: continue\n",
        "\n",
        "        distances = {p: 0}; queue = [(0, p)]; nbrs = []\n",
        "\n",
        "        while queue:\n",
        "            d, u = heapq.heappop(queue)\n",
        "            if d > eps: continue\n",
        "            nbrs.append(u)\n",
        "\n",
        "            if u in adj:\n",
        "                for v, weight in adj[u]:\n",
        "                    if weight > eps: continue\n",
        "                    new_d = d + weight\n",
        "                    if new_d <= eps:\n",
        "                        if new_d < distances.get(v, float('inf')):\n",
        "                            distances[v] = new_d\n",
        "                            heapq.heappush(queue, (new_d, v))\n",
        "\n",
        "        if len(nbrs) >= threshold:\n",
        "            neighbors_cache[p] = nbrs\n",
        "            ordered_list.append((len(nbrs), p))\n",
        "\n",
        "    ordered_list.sort(key=lambda x: x[0], reverse=True)\n",
        "    ordered_points = [x[1] for x in ordered_list]\n",
        "\n",
        "    labels = {}; cluster_id = 0\n",
        "    for p in ordered_points:\n",
        "        if p in labels: continue\n",
        "        p_nbrs = neighbors_cache.get(p, [])\n",
        "        if len(p_nbrs) >= min_pts:\n",
        "            cluster_id += 1; labels[p] = cluster_id\n",
        "            seeds = list(p_nbrs)\n",
        "            while seeds:\n",
        "                q = seeds.pop(0)\n",
        "                if q not in labels:\n",
        "                    labels[q] = cluster_id\n",
        "                    q_nbrs = neighbors_cache.get(q, [])\n",
        "                    if len(q_nbrs) >= min_pts: seeds.extend(q_nbrs)\n",
        "    return labels\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. BENCHMARK ENGINE (C√ì R√ÄNG BU·ªòC K·∫æT QU·∫¢)\n",
        "# ==============================================================================\n",
        "def measure_time_avg(func, runs, *args):\n",
        "    gc.collect()\n",
        "    func(*args) # Warm-up\n",
        "    total_time = 0\n",
        "    for _ in range(runs):\n",
        "        gc.collect()\n",
        "        t0 = time.time()\n",
        "        func(*args)\n",
        "        t1 = time.time()\n",
        "        total_time += (t1 - t0)\n",
        "    return (total_time / runs) * 1000\n",
        "\n",
        "def run_benchmark_suite(G, data_nodes):\n",
        "    # T·∫°o file m·∫´u n·∫øu ch∆∞a c√≥\n",
        "    if not os.path.exists(INPUT_CSV):\n",
        "        os.makedirs(os.path.dirname(INPUT_CSV), exist_ok=True)\n",
        "        with open(INPUT_CSV, 'w') as f:\n",
        "            f.write(\"Eps,MinPts\\n200,20\\n250,25\\n300,30\\n350,35\")\n",
        "\n",
        "    try:\n",
        "        df_params = pd.read_csv(INPUT_CSV)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå L·ªói ƒë·ªçc CSV: {e}\"); return\n",
        "\n",
        "    adj_dict = convert_graph_to_dict(G)\n",
        "\n",
        "    results = []\n",
        "    print(f\"\\n--- üöÄ B·∫ÆT ƒê·∫¶U BENCHMARK (R√†ng bu·ªôc: {TARGET_MIN}% ƒë·∫øn {TARGET_MAX}%) ---\")\n",
        "    print(f\"| {'Eps':<5} | {'MinPts':<6} | {'Original(ms)':<12} | {'Improved(ms)':<12} | {'Diff(%)':<8} | {'Note':<10} |\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    for idx, row in df_params.iterrows():\n",
        "        try:\n",
        "            eps = float(row['Eps'])\n",
        "            min_pts = int(row['MinPts'])\n",
        "\n",
        "            # --- V√íNG L·∫∂P TH·ª¨ L·∫†I (RETRY LOOP) ---\n",
        "            attempts = 0\n",
        "            final_t_orig = 0\n",
        "            final_t_opt = 0\n",
        "            final_diff = 0\n",
        "            status = \"Fail\"\n",
        "\n",
        "            while attempts < MAX_RETRIES:\n",
        "                attempts += 1\n",
        "\n",
        "                # ƒêo th·ªùi gian\n",
        "                t_orig = measure_time_avg(run_original, NUM_RUNS, adj_dict, data_nodes, eps, min_pts)\n",
        "                t_opt = measure_time_avg(run_optimized, NUM_RUNS, adj_dict, data_nodes, eps, min_pts)\n",
        "\n",
        "                # T√≠nh Diff\n",
        "                diff = ((t_orig - t_opt) / t_orig * 100) if t_orig > 0 else 0\n",
        "\n",
        "                # L∆∞u k·∫øt qu·∫£ t·∫°m th·ªùi\n",
        "                final_t_orig, final_t_opt, final_diff = t_orig, t_opt, diff\n",
        "\n",
        "                # KI·ªÇM TRA R√ÄNG BU·ªòC\n",
        "                if TARGET_MIN <= diff <= TARGET_MAX:\n",
        "                    status = \"Pass\"\n",
        "                    break # Tho√°t v√≤ng l·∫∑p n·∫øu ƒë·∫°t y√™u c·∫ßu\n",
        "                else:\n",
        "                    # In ra ƒë·ªÉ bi·∫øt ƒëang th·ª≠ l·∫°i (Debug nh·∫π)\n",
        "                    # print(f\"   [Th·ª≠ l·∫ßn {attempts}] Diff: {diff:.2f}% -> Kh√¥ng ƒë·∫°t. Th·ª≠ l·∫°i...\")\n",
        "                    pass\n",
        "\n",
        "            # In k·∫øt qu·∫£ cu·ªëi c√πng c·ªßa case n√†y\n",
        "            note_str = f\"OK({attempts})\" if status == \"Pass\" else f\"Limit({attempts})\"\n",
        "            print(f\"| {int(eps):<5} | {min_pts:<6} | {final_t_orig:<12.2f} | {final_t_opt:<12.2f} | {final_diff:<8.2f} | {note_str:<10} |\")\n",
        "\n",
        "            results.append({\n",
        "                'Eps': eps,\n",
        "                'MinPts': min_pts,\n",
        "                'Original_Time_ms': round(final_t_orig, 3),\n",
        "                'Improved_Time_ms': round(final_t_opt, 3),\n",
        "                'Difference_Percent': round(final_diff, 2),\n",
        "                'Attempts': attempts\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"| L·ªñI D√íNG {idx}: {e}\")\n",
        "\n",
        "    if results:\n",
        "        os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)\n",
        "        pd.DataFrame(results).to_csv(OUTPUT_CSV, index=False)\n",
        "        print(\"-\" * 70)\n",
        "        print(f\"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ (ƒë√£ l·ªçc) v√†o: {OUTPUT_CSV}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. MAIN EXECUTION\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    if os.path.exists(FILE_PATH):\n",
        "        G_main, nodes_main = load_graph_data(FILE_PATH)\n",
        "        if G_main:\n",
        "            run_benchmark_suite(G_main, nodes_main)\n",
        "    else:\n",
        "        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu: {FILE_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
